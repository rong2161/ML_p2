{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j46tyzVL--pL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6306d691-ebb3-485b-e02a-51272a0990da"
      },
      "source": [
        "# Rong\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "train_path = 'gdrive/My Drive/MiniP-2/train.csv'\n",
        "test_path = 'gdrive/My Drive/MiniP-2/test.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BybK2FZgArQD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4fKC6DTAXqI"
      },
      "source": [
        "# Part 1. Using the data provided in train.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxOHO_q-3dFh"
      },
      "source": [
        "## 1. Implement Bernoulli Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e3vaRBK3sHZ"
      },
      "source": [
        "##2. Additional experiments using other classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua4r6ExwETZf"
      },
      "source": [
        "train = pd.read_csv(train_path)\n",
        "train_X = train['body']\n",
        "train_Y = train['subreddit']\n",
        "\n",
        "#test = pd.read_csv(test_path)\n",
        "#test_X = test['body']\n",
        "#train.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNG6cDvq3908"
      },
      "source": [
        "### 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wzmpPPg5OcK"
      },
      "source": [
        "tf_idf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_X, train_Y, train_size=0.7, test_size=0.3)\n",
        "\n",
        "vectors_train = tf_idf_vectorizer.fit_transform(x_train)\n",
        "vectors_test = tf_idf_vectorizer.transform(x_test)\n",
        "\n",
        "normalizer_train = Normalizer().fit(X=vectors_train)\n",
        "\n",
        "vectors_train_normalized = normalizer_train.transform(vectors_train)\n",
        "vector_test_normalized = normalizer_train.transform(vectors_test)\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "\n",
        "lr_model.fit(vectors_train, y_train)\n",
        "lr_pred = lr_model.predict(vector_test_normalized)\n",
        "\n",
        "print((y_test == lr_pred).mean())\n",
        "print(metrics.classification_report(y_test, lr_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lXtcoAj4Ije"
      },
      "source": [
        "###2. LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRX4ZZaP5PSG"
      },
      "source": [
        "tf_idf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_X, train_Y, train_size=0.7, test_size=0.3)\n",
        "\n",
        "vectors_train = tf_idf_vectorizer.fit_transform(x_train)\n",
        "vectors_test = tf_idf_vectorizer.transform(x_test)\n",
        "\n",
        "normalizer_train = Normalizer().fit(X=vectors_train)\n",
        "\n",
        "vectors_train_normalized = normalizer_train.transform(vectors_train)\n",
        "vector_test_normalized = normalizer_train.transform(vectors_test)\n",
        "\n",
        "l_SVC_model = LinearSVC(class_weight='balanced',multi_class='crammer_singer')\n",
        "\n",
        "l_SVC_model.fit(vectors_train, y_train)\n",
        "l_SVC_pred = l_SVC_model.predict(vector_test_normalized)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, l_SVC_pred))\n",
        "print(metrics.classification_report(y_test, l_SVC_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43cr6hSci1Nr"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "n_sample = len(x_train)\n",
        "tuned_parameters = [{'C': [1, 10, 100, 1000, 10000],}]\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(\n",
        "        LinearSVC(), tuned_parameters, scoring='%s_macro' % score\n",
        "    )\n",
        "    clf.fit(vectors_train,  y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9It19VdE4WtA"
      },
      "source": [
        "###3. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGdbso6A5P7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6245e10-3cb1-4181-ec2d-a5cdac9f9e88"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tf_idf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_X, train_Y, train_size=0.7, test_size=0.3)\n",
        "\n",
        "vectors_train = tf_idf_vectorizer.fit_transform(x_train)\n",
        "vectors_test = tf_idf_vectorizer.transform(x_test)\n",
        "\n",
        "normalizer_train = Normalizer().fit(X=vectors_train)\n",
        "\n",
        "vectors_train_normalized = normalizer_train.transform(vectors_train)\n",
        "vector_test_normalized = normalizer_train.transform(vectors_test)\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "\n",
        "dt_model.fit (vectors_train, y_train)\n",
        "dt_pred = dt_model.predict(vector_test_normalized)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, dt_pred))\n",
        "print(metrics.classification_report(y_test, dt_pred))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6886330935251799\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anime       0.78      0.79      0.78       372\n",
            "        cars       0.78      0.79      0.79       645\n",
            "   computers       0.43      0.32      0.36       130\n",
            " datascience       0.78      0.83      0.80       730\n",
            "     gamedev       0.49      0.47      0.48       296\n",
            "   gamernews       0.41      0.43      0.42       235\n",
            "    hardware       0.62      0.62      0.62       489\n",
            "         rpg       0.73      0.68      0.70       578\n",
            "\n",
            "    accuracy                           0.69      3475\n",
            "   macro avg       0.63      0.62      0.62      3475\n",
            "weighted avg       0.68      0.69      0.69      3475\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vosoD0qM5SIL"
      },
      "source": [
        "## 3. Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_91vggvi5aMe"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from copy import deepcopy\n",
        "\n",
        "def model_valid(model, features_X, target_Y, vectorizer, k_fold=3):\n",
        "    kf = KFold(n_splits=k_fold)\n",
        "    counter = 1\n",
        "    ave = 0\n",
        "       \n",
        "    for train_index, test_index in kf.split(features_X, target_Y):\n",
        "      tempMod = deepcopy(model)\n",
        "      vectors_train = vectorizer.fit_transform(features_X[train_index])\n",
        "      vectors_test = vectorizer.transform(features_X[test_index])\n",
        "      normalizer_train = Normalizer().fit(X=vectors_train)\n",
        "      vectors_train_normalized = normalizer_train.transform(vectors_train)\n",
        "      vectors_test_normalized = normalizer_train.transform(vectors_test)\n",
        "      \n",
        "      tempMod.fit(vectors_train, target_Y[train_index])\n",
        "      #y_pred = tempMod.predict(vector_test_normalized)\n",
        "      # ave += (y_pred == target_Y[test_index]).mean() \n",
        "      # print(ave)\n",
        "      # print(counter)\n",
        "      # counter+=1\n",
        "\n",
        "    return #ave/k_fold;\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6bsUVQ4PU9Z"
      },
      "source": [
        "# Classifier Running Default\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O3qo1zWTNed"
      },
      "source": [
        "## Logistic Regression default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTm-8u1YPg_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58be8d3c-82d3-4da8-a2cc-3be852cc9c97"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "tf_idf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "vectors_X = tf_idf_vectorizer.fit_transform(train_X)\n",
        "\n",
        "vectors_train, vectors_test, y_train, y_test = train_test_split(vectors_X, train_Y, train_size=0.7, test_size=0.3)\n",
        "\n",
        "\n",
        "normalizer_train = Normalizer().fit(X=vectors_train)\n",
        "vectors_train_normalized = normalizer_train.transform(vectors_train)\n",
        "vector_test_normalized = normalizer_train.transform(vectors_test)\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "lr_model.fit(vectors_train, y_train)\n",
        "lr_pred = lr_model.predict(vector_test_normalized)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, lr_pred))\n",
        "print(metrics.classification_report(y_test, lr_pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8627338129496402\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anime       0.95      0.90      0.92       404\n",
            "        cars       0.85      0.97      0.90       603\n",
            "   computers       0.86      0.37      0.52       118\n",
            " datascience       0.89      0.95      0.92       736\n",
            "     gamedev       0.90      0.66      0.76       300\n",
            "   gamernews       0.85      0.55      0.66       222\n",
            "    hardware       0.79      0.86      0.82       495\n",
            "         rpg       0.84      0.94      0.89       597\n",
            "\n",
            "    accuracy                           0.86      3475\n",
            "   macro avg       0.87      0.77      0.80      3475\n",
            "weighted avg       0.87      0.86      0.86      3475\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnkbiK6nFsS_"
      },
      "source": [
        "## Decision Tree Defalut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlpnVR71T-KZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5116db06-15dc-495e-8c42-d34301361021"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "\n",
        "dt_model.fit (vectors_train, y_train)\n",
        "dt_pred = dt_model.predict(vector_test_normalized)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, dt_pred))\n",
        "print(metrics.classification_report(y_test, dt_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.695251798561151\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anime       0.81      0.76      0.79       389\n",
            "        cars       0.79      0.79      0.79       629\n",
            "   computers       0.43      0.35      0.39       138\n",
            " datascience       0.82      0.82      0.82       744\n",
            "     gamedev       0.52      0.48      0.50       326\n",
            "   gamernews       0.41      0.50      0.45       228\n",
            "    hardware       0.65      0.62      0.64       460\n",
            "         rpg       0.67      0.71      0.69       561\n",
            "\n",
            "    accuracy                           0.70      3475\n",
            "   macro avg       0.64      0.63      0.63      3475\n",
            "weighted avg       0.70      0.70      0.70      3475\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAqNOQxphYNC"
      },
      "source": [
        "## Linear support vector machine default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P44FkLEheiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0633ff-8d6a-4915-edb5-cf451ebca0d9"
      },
      "source": [
        "from sklearn.svm import LinearSVC \n",
        "\n",
        "l_SVC_model = LinearSVC()\n",
        "\n",
        "l_SVC_model.fit(vectors_train, y_train)\n",
        "l_SVC_pred = l_SVC_model.predict(vector_test_normalized)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, l_SVC_pred))\n",
        "print(metrics.classification_report(y_test, l_SVC_pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8776978417266187\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anime       0.96      0.95      0.95       389\n",
            "        cars       0.91      0.94      0.92       629\n",
            "   computers       0.84      0.63      0.72       138\n",
            " datascience       0.92      0.96      0.94       744\n",
            "     gamedev       0.84      0.76      0.80       326\n",
            "   gamernews       0.70      0.67      0.68       228\n",
            "    hardware       0.83      0.81      0.82       460\n",
            "         rpg       0.88      0.91      0.90       561\n",
            "\n",
            "    accuracy                           0.88      3475\n",
            "   macro avg       0.86      0.83      0.84      3475\n",
            "weighted avg       0.88      0.88      0.88      3475\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwvXZmQeBPl4"
      },
      "source": [
        "train = pd.read_csv(train_path)\n",
        "#test = pd.read_csv(test_path)\n",
        "#test_X = test['body']\n",
        "#train.head()\n",
        "\n",
        "train_X = train['body']\n",
        "train_Y = train['subreddit']\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(train_X, train_Y, train_size=0.7, test_size=0.3)\n",
        "\n",
        "\n",
        "tf_idf_vectorizer = TfidfVectorizer(binary=True, max_features=5000, stop_words='english')\n",
        "\n",
        "vectors_X = tf_idf_vectorizer.fit_transform(train_X)\n",
        "\n",
        "vectors_train, vectors_test, y_train, y_test = train_test_split(vectors_X, train_Y, train_size=0.7, test_size=0.3)\n",
        "\n",
        "# vectors_train = tf_idf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "#print(vectors_train)\n",
        "\n",
        "# vectors_test = tf_idf_vectorizer.fit_transform(X_test)\n",
        "\n",
        "\n",
        "normalizer_train = Normalizer().fit(X=vectors_train)\n",
        "vectors_train_normalized = normalizer_train.transform(vectors_train)\n",
        "vector_test_normalized = normalizer_train.transform(vectors_test)\n",
        "\n",
        "#print(vectors_train_normalized)\n",
        "\n",
        "\n",
        "BNB = BernoulliNB()\n",
        "\n",
        "BNB.fit(vectors_train_normalized, y_train)\n",
        "\n",
        "y_pred = BNB.predict(vector_test_normalized)\n",
        "\n",
        "\n",
        "print (metrics.accuracy_score(y_test, y_pred)) \n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}